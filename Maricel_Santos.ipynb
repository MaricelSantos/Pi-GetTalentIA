{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92de8ca4-7181-45f5-9980-b723d2566f5e",
   "metadata": {},
   "source": [
    "# Challenge Prompting\n",
    "\n",
    "Resolver los siguientes ejercicios dejando el codigo con su ejecucion.\n",
    "\n",
    "Importar las librerias necesarias y **correr las celdas para visualizar el resultado en cada ejercicio**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d65bbb09-0f5a-4e97-9a06-2361c5cdd1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## bloque importacion de librerias\n",
    "\n",
    "import json\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e004e5b7-b704-4592-b8b4-b01b8d6687cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOepoIgRKX8xB0mGePFoatDW0vSWgcFLVxa9xbhq\n"
     ]
    }
   ],
   "source": [
    "## bloque variables de entorno\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Load .env file\n",
    "\n",
    "api_key = os.getenv(\"COHERE_API_KEY\")\n",
    "print(api_key)  # Verify the key is loaded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd6745ff-cd45-4231-b3d6-518954a9ffca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id='c03b7f53-2e14-4923-ab2d-2282d9e52951' finish_reason='COMPLETE' prompt=None message=AssistantMessageResponse(role='assistant', tool_calls=None, tool_plan=None, content=[TextAssistantMessageResponseContentItem(type='text', text='Soy Command R+ 08-2024, un modelo de lenguaje de gran tama√±o desarrollado por la empresa Cohere. Estoy dise√±ado para ayudar a los usuarios humanos proporcionando respuestas detalladas y sofisticadas. Mi objetivo es ofrecer informaci√≥n √∫til, responder preguntas y ayudar en diversas tareas a trav√©s de conversaciones naturales y fluidas.\\n\\nSi deseas saber m√°s sobre mis capacidades o tienes alguna otra pregunta, no dudes en preguntar. Estoy aqu√≠ para ayudarte.')], citations=None) usage=Usage(billed_units=UsageBilledUnits(input_tokens=4.0, output_tokens=98.0, search_units=None, classifications=None), tokens=UsageTokens(input_tokens=205.0, output_tokens=98.0)) logprobs=None\n",
      "Soy Command R+ 08-2024, un modelo de lenguaje de gran tama√±o desarrollado por la empresa Cohere. Estoy dise√±ado para ayudar a los usuarios humanos proporcionando respuestas detalladas y sofisticadas. Mi objetivo es ofrecer informaci√≥n √∫til, responder preguntas y ayudar en diversas tareas a trav√©s de conversaciones naturales y fluidas.\n",
      "\n",
      "Si deseas saber m√°s sobre mis capacidades o tienes alguna otra pregunta, no dudes en preguntar. Estoy aqu√≠ para ayudarte.\n"
     ]
    }
   ],
   "source": [
    "## bloque conexion a Cohere\n",
    "\n",
    "import cohere\n",
    "co = cohere.ClientV2(log_warning_experimental_features=False)\n",
    "# alternativa:\n",
    "# co = cohere.ClientV2(api_key)\n",
    "\n",
    "response = co.chat(\n",
    "    model=\"command-r-plus-08-2024\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"qui√©n sos?\"}],\n",
    ")\n",
    "\n",
    "print(response)\n",
    "print(response.message.content[0].text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aacdb26-ce51-49cc-b37f-5aa45c09ff51",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "\n",
    "Extraccion de entidades\n",
    "\n",
    "Utilizar el LLM para extraer las siguientes entidades del texto medico.\n",
    "\n",
    "- Paciente:\n",
    "    - Nombre\n",
    "    - Edad\n",
    "- Fecha de admisi√≥n\n",
    "- S√≠ntomas\n",
    "- Diagn√≥stico\n",
    "- Tratamiento recomendado\n",
    "\n",
    "**Aclaracion:** \n",
    "\n",
    "La salida tiene que ser un **string con formato de tipo json**, el cual se convertira en un diccionario de Python.\n",
    "\n",
    "Si la linea de conversion en test da error el ejercicio no esta completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750e43d7-b074-4973-9cd0-5a6fbe816084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo \n",
    "\n",
    "# texto a analizar\n",
    "\"\"\"La paciente, Mar√≠a Gonz√°lez, de 45 a√±os, fue admitida en el Hospital Central el 5 de agosto de 2023 debido a s√≠ntomas de fatiga cr√≥nica y dolores musculares./\n",
    "Tras una serie de an√°lisis, se diagnostic√≥ fibromialgia. La doctora a cargo, Laura Ram√≠rez, recomend√≥ un tratamiento basado en fisioterapia y medicamentos analg√©sicos. /\n",
    "La pr√≥xima consulta est√° programada para el 15 de septiembre.\"\"\"\n",
    "\n",
    "\n",
    "# respuesta del LLM\n",
    "{\n",
    "  \"paciente\": {\n",
    "    \"nombre\": \"Mar√≠a Gonz√°lez\",\n",
    "    \"edad\": 45\n",
    "  },\n",
    "  \"fecha_admision\": \"2023-08-05\",\n",
    "  \"sintomas\": [\n",
    "    \"fatiga cr√≥nica\",\n",
    "    \"dolores musculares\"\n",
    "  ],\n",
    "  \"diagnostico\": \"fibromialgia\",\n",
    "  \"tratamiento\": [\n",
    "    \"fisioterapia\",\n",
    "    \"medicamentos analg√©sicos\"\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38d9cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Soluci√≥n propuesta\n",
    "\n",
    "def datos_pacientes(consulta):\n",
    "    \"\"\"\n",
    "    Leer datos de pacientes en historias clinicas y extraer datos.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"Extrae datos del paciente en formato JSON\n",
    "    \n",
    "             texto: ''' {consulta} ''' \n",
    "\n",
    "            Datos paciente:\n",
    "            - Paciente:\n",
    "                - Nombre\n",
    "                - Edad\n",
    "            - Fecha de admisi√≥n\n",
    "            - S√≠ntomas (lista)\n",
    "            - Diagn√≥stico\n",
    "            - Tratamiento recomendado (lista)\n",
    "    \"\"\"\n",
    "    response = co.chat(\n",
    "        model=\"command-r-plus-08-2024\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\":\"Extrae datos de pacientes a partir de la historia clinica\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    \n",
    "    return response.message.content[0].text\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "04ef7446",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_analize = \"\"\"La paciente, Mar√≠a Gonz√°lez, de 45 a√±os, fue admitida en el Hospital Central el 5 de agosto de 2023 debido a s√≠ntomas de fatiga cr√≥nica y dolores musculares./\n",
    "Tras una serie de an√°lisis, se diagnostic√≥ fibromialgia. La doctora a cargo, Laura Ram√≠rez, recomend√≥ un tratamiento basado en fisioterapia y medicamentos analg√©sicos. /\n",
    "La pr√≥xima consulta est√° programada para el 15 de septiembre.\"\"\"\n",
    "\n",
    "caso_1 = \"Cardiopat√≠a isqu√©mica - La paciente, Rosa Mart√≠nez, de 62 a√±os, ingres√≥ al Hospital San Jos√© el 12 de junio de 2024 por presentar dolor tor√°cico persistente y dificultad para respirar. / Los ex√°menes de electrocardiograma y an√°lisis de enzimas card√≠acas confirmaron un infarto agudo de miocardio. / El doctor Pedro Garc√≠a realiz√≥ una angioplastia de emergencia con √©xito, y la paciente fue derivada a rehabilitaci√≥n card√≠aca. / Su control postoperatorio est√° programado para el 20 de junio.\"\n",
    "caso_2 = \"Diabetes mellitus tipo 2 - El paciente, Juan L√≥pez, de 54 a√±os, acudi√≥ al Centro M√©dico de la Ciudad el 15 de mayo de 2023 debido a fatiga constante, sed excesiva y p√©rdida de peso involuntaria. / Los an√°lisis de sangre revelaron niveles de glucosa de 280 mg/dL en ayunas y hemoglobina glicosilada elevada, diagnostic√°ndose diabetes tipo 2. / La endocrin√≥loga Clara Fern√°ndez inici√≥ tratamiento con metformina y cambios en la dieta. / Su pr√≥xima consulta de seguimiento ser√° el 10 de junio.\"\n",
    "\n",
    "caso_3 = \"Apendicitis aguda - El paciente, Lucas Rodr√≠guez, de 28 a√±os, se present√≥ en la guardia del Hospital General el 8 de marzo de 2024 con dolor abdominal agudo en la fosa iliaca derecha, fiebre y n√°useas. / Una ecograf√≠a abdominal confirm√≥ apendicitis aguda. / Fue sometido a una apendicectom√≠a laparosc√≥pica realizada por el cirujano Carlos M√©ndez. / El alta m√©dica se otorg√≥ el 10 de marzo con indicaciones de reposo y control de signos de infecci√≥n. / El seguimiento est√° programado para el 18 de marzo.\"\n",
    "\n",
    "caso_4 = \"Asma bronquial - Mar√≠a Fern√°ndez, de 32 a√±os, consult√≥ en la Cl√≠nica Respiratoria el 25 de abril de 2023 por episodios recurrentes de sibilancias, tos y dificultad para respirar, especialmente durante la noche. / Las pruebas de funci√≥n pulmonar confirmaron un diagn√≥stico de asma moderada persistente. / La neum√≥loga Ana L√≥pez recet√≥ un inhalador con corticosteroides y broncodilatadores de acci√≥n r√°pida para uso seg√∫n necesidad. / Un control de seguimiento se agend√≥ para el 25 de mayo.\"\n",
    "\n",
    "caso_5 = text_to_analize\n",
    "\n",
    "\n",
    "casos = [globals()[f\"caso_{i}\"] for i in range(1, 6)]\n",
    "\n",
    "\n",
    "resultados = [datos_pacientes(caso) for caso in casos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c36e919d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"paciente\": {\n",
      "        \"nombre\": \"Juan L√≥pez\",\n",
      "        \"edad\": 54\n",
      "    },\n",
      "    \"fecha_admision\": \"15 de mayo de 2023\",\n",
      "    \"sintomas\": [\n",
      "        \"Fatiga constante\",\n",
      "        \"Sed excesiva\",\n",
      "        \"P√©rdida de peso involuntaria\"\n",
      "    ],\n",
      "    \"diagnostico\": \"Diabetes mellitus tipo 2\",\n",
      "    \"tratamiento\": [\n",
      "        \"Metformina\",\n",
      "        \"Cambios en la dieta\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(resultados[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6f0009-8a9c-49a3-b740-d73e0dbe765e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'paciente': {'nombre': 'Juan L√≥pez', 'edad': 54}, 'fecha_admision': '15 de mayo de 2023', 'sintomas': ['Fatiga constante', 'Sed excesiva', 'P√©rdida de peso involuntaria'], 'diagnostico': 'Diabetes mellitus tipo 2', 'tratamiento': ['Metformina', 'Cambios en la dieta']}\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "final_result1 = json.loads(resultados[1])\n",
    "print(final_result1)\n",
    "# test todos los ejemplso\n",
    "final_result = [json.loads(resultado) for resultado in resultados]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37fbf25-6db4-432a-82c4-2e7edce27686",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "\n",
    "Tenemos dos funciones en Python, una llamada *'add_contact'* y otra llamada *'get_information'*.\n",
    "\n",
    "**Utilizar algun LLM que permita funtion calling** y desarrollar un codigo secuencial automatico que consiga:\n",
    "\n",
    "Interpretar la consulta del usuario, identificar a que funcion llamar, luego llamarla (si es que aplica) y darle una respuesta final al usuario.  (usar function calling para esta solucion)\n",
    "\n",
    "La entrada a dicho codigo es la consulta del usuario, a continuacion algunos ejemplos:\n",
    "\n",
    "- \"Agrega a Juan P√©rez con el n√∫mero 555-1234 y el correo juanperez@mail.com.\"\n",
    "- \"Guarda a Luc√≠a G√≥mez en mis contactos. Su tel√©fono es 555-5678 y su email es lucia.gomez@gmail.com.\"\n",
    "- \"Cual es el Email de Juan P√©rez.?\"\n",
    "\n",
    "Salidas esperadas de dichos ejemplos (variaran porque las genera el LLM):\n",
    "-  El contacto fue anadido con exito\n",
    "-  Se anadio el contacto\n",
    "-  El email de juan perez es juanperez@mail.com\n",
    "\n",
    "Link de ayuda: https://github.com/cohere-ai/notebooks/blob/main/notebooks/agents/Vanilla_Tool_Use_v2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3632856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "contacts = {\n",
    "                        'Joaquin Lopez':{'tel': 15456663258, 'mail': 'Joacolocolopez@gmail.com'},\n",
    "                      'Flavio Oncativo':{'tel': 1545554178, 'mail': 'FOncativo@hotmail.com'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c6e43cb9-5e6a-4807-9818-c85408f1ba58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_contact(name, phone, email):\n",
    "    \"\"\"\n",
    "    Agrega un contacto al diccionario.\n",
    "    Par√°metros:\n",
    "        name (str): Nombre del contacto.\n",
    "        phone (str): N√∫mero de tel√©fono del contacto.\n",
    "        email (str): Correo electr√≥nico del contacto.\n",
    "    Retorna:\n",
    "        str: Mensaje confirmando la adici√≥n del contacto.\n",
    "    \"\"\"\n",
    "    contacts[name] = {'phone': phone, 'email': email}\n",
    "    return \"Contacto anadido con exito.\"\n",
    "\n",
    "def get_information(name):\n",
    "    \"\"\"\n",
    "    Recupera la informaci√≥n de un contacto.\n",
    "    Par√°metros:\n",
    "        name (str): Nombre del contacto.\n",
    "    Retorna:\n",
    "        dict/str: Informaci√≥n del contacto o un mensaje si no existe.\n",
    "    \"\"\"\n",
    "    if name in contacts:\n",
    "        return contacts[name]\n",
    "    else:\n",
    "        return \"Contacto no encontrado.\"\n",
    "    \n",
    "functions_map = {\n",
    "    \"add_contact\": add_contact,\n",
    "    \"get_information\": get_information\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "09bf5950",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"add_contact\",\n",
    "            \"description\": \"Agrega un contacto al diccionario.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"name\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Nombre del contacto.\"\n",
    "                    },\n",
    "                    \"phone\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"N√∫mero de tel√©fono del contacto.\"\n",
    "                    },\n",
    "                    \"email\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Correo electr√≥nico del contacto.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"name\", \"phone\", \"email\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_information\",\n",
    "            \"description\": \"Recupera la informaci√≥n de un contacto.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"name\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Nombre del contacto.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"name\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c58b6496",
   "metadata": {},
   "outputs": [],
   "source": [
    "preamble = \"\"\"\n",
    "## Task and Context\n",
    "You help people to add contacts, emails and phones.You have instructions ans tools to do that. \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# user request\n",
    "request = \"Agrega a Juan P√©rez con el n√∫mero 555-1234 y el correo juanperez@mail.com.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b8cf1239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model recommends doing the following tool calls:\n",
      "\n",
      "Tool plan:\n",
      "I will add the contact using the add_contact tool. \n",
      "\n",
      "Tool calls:\n",
      "Tool name: add_contact | Parameters: {\"email\":\"juanperez@mail.com\",\"name\":\"Juan P√©rez\",\"phone\":\"555-1234\"}\n"
     ]
    }
   ],
   "source": [
    "messages=[{\"role\": \"system\", \"content\": preamble},\n",
    "          {\"role\": \"user\", \"content\": request}]\n",
    "\n",
    "response = co.chat(\n",
    "    model=\"command-r-plus\",\n",
    "    messages=messages,\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "print(\"The model recommends doing the following tool calls:\\n\")\n",
    "print(\"Tool plan:\")\n",
    "print(response.message.tool_plan,\"\\n\")\n",
    "print(\"Tool calls:\")\n",
    "for tc in response.message.tool_calls:\n",
    "    print(f\"Tool name: {tc.function.name} | Parameters: {tc.function.arguments}\")\n",
    "    \n",
    "# append the chat history\n",
    "messages.append({'role': 'assistant', 'tool_calls': response.message.tool_calls, 'tool_plan': response.message.tool_plan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a5f82faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool results that will be fed back to the model in step 4:\n",
      "\"Contacto anadido con exito.\"\n"
     ]
    }
   ],
   "source": [
    "tool_content = []\n",
    "# Iterate over the tool calls generated by the model\n",
    "for tc in response.message.tool_calls:\n",
    "    # here is where you would call the tool recommended by the model, using the parameters recommended by the model\n",
    "    tool_result= functions_map[tc.function.name](**json.loads(tc.function.arguments))\n",
    "    # store the output in a list\n",
    "    tool_content.append(json.dumps(tool_result))\n",
    "    # append the chat history\n",
    "    messages.append({'role': 'tool', 'tool_call_id': tc.id, 'content': tool_content}) \n",
    "\n",
    "print(\"Tool results that will be fed back to the model in step 4:\")\n",
    "for result in tool_content:\n",
    "    print(json.dumps(json.loads(result), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8a09230a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final answer:\n",
      "Contacto a√±adido con √©xito.\n"
     ]
    }
   ],
   "source": [
    "response = co.chat(\n",
    "    model=\"command-r-plus\",\n",
    "    messages=messages,\n",
    "    tools=tools\n",
    ")\n",
    "print(\"Final answer:\")\n",
    "print(response.message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36ef67d-dd54-41e7-bef5-f89ee575603f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TIPS\n",
    "# Probar primero generando una funcion y llamarla, luego anadir la otra\n",
    "# Plantearlo paso por paso en distintas celdas, analizar las salidas y las entradas, como identificamos a que funcion llamar?\n",
    "# luego automatizar dentro de una sola celda\n",
    "\n",
    "\n",
    "# Lo importante es entregar hasta donde lleguen, sea una funcion, las dos pero sin poder hacer el flujo automatico, lo que puedan, siempre y cuando este\n",
    "# claro lo que se quizo hacer con comentarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d8badf-dc90-4005-b916-8e528105d797",
   "metadata": {},
   "source": [
    "## Ejercicio 3\n",
    "\n",
    "Crear una funcion llamada \"history_answer\", que toma como parametro de entrada una pregunta sobre un contexto dado y la salida es la respuesta final del proceso impulsado por un LLM.\n",
    "\n",
    "Dada una historia, el usuario podra hacer preguntas sobre la misma y el LLM debe responder siguiendo los siguientes lineamientos:\n",
    "\n",
    "REQUISITOS DE LA RESPUESTA\n",
    "- las respuestas deben ser en base a la historia\n",
    "- ante la misma pregunta siempre debe responder de la misma manera.\n",
    "- que responda en solo una oracion.\n",
    "- el idioma que responde debe ser el mismo que con el que se pregunta (ingles, espanol, portugues).\n",
    "- que agregue emojis en la oracion que resuman el contenido de la misma.\n",
    "- que responda siempre en tercera persona.\n",
    "- si la pregunta no tiene relacion alguna con el contexto, la respuesta debe ser 'Lo siento no puedo ayudarte con eso'.\n",
    "- Responder con 'Hakuna Matata!' al final de **todas** las respuestas (no importa idioma ni cantidad de tokens).\n",
    "\n",
    "**Ayudin**: \n",
    "- No se limiten a usar 1 solo request al LLM, pueden dividirlo en partes para que por un lado se verifique el idioma, por otro lado se verifique si la pregunta tiene relacion con el contexto, etc\n",
    "\n",
    "- Estructuren bien el prompt procurando separar instrucciones, contexto(historia) y pregunta del usuario.\n",
    "\n",
    "- Recuerden usar el system message y user message.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f36820-b7d3-4813-a0c3-351c598106ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo flojo de estructura de prompt\n",
    "# prompt = f\"Responde a la pregunta: {pregunta} de manera concisa y divertida en base a la siguiente historia: {historia}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5602f56-4032-4cc6-a2c5-7b29cf2a2a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La historia tuvo lugar en un feudo medieval, donde la guerra y la batalla marcaron el destino de Thomas. üè∞üó°Ô∏è Hakuna Matata!\n",
      "History took place in a medieval fiefdom, where war and battle shaped Thomas's destiny. üè∞üó°Ô∏è Hakuna Matata!\n"
     ]
    }
   ],
   "source": [
    "# Primera iteracion\n",
    "historia = \"\"\"En un peque√±o feudo medieval, Thomas, un joven campesino de diecis√©is a√±os, trabajaba desde el amanecer en los campos de trigo del se√±or feudal. El sol apenas hab√≠a salido cuando √©l ya hab√≠a arado m√°s de lo que sus manos pod√≠an soportar. La vida era dura, pero su familia depend√≠a de la cosecha para pagar los impuestos y mantener su hogar de madera y paja.\n",
    "\n",
    "Un d√≠a, el feudo fue sacudido por noticias de guerra. El rey hab√≠a llamado a todos los hombres en edad de luchar. Thomas sab√≠a que, al igual que otros j√≥venes, no ten√≠a elecci√≥n. Cambi√≥ la hoz por una lanza rudimentaria y se uni√≥ a la milicia local. Sin entrenamiento, fue empujado a un campo de batalla embarrado, donde el acero resonaba y los gritos de los hombres llenaban el aire.\n",
    "\n",
    "La batalla fue un caos. Thomas, con el coraz√≥n latiendo en su pecho como un tambor de guerra, apenas pod√≠a distinguir amigo de enemigo. Logr√≥ esquivar una espada, pero cay√≥ al suelo, cubierto de lodo y sangre. Levant√°ndose, vio c√≥mo un compa√±ero ca√≠a junto a √©l, sus ojos abiertos, vac√≠os.\n",
    "\n",
    "Cuando la batalla termin√≥, el silencio era tan profundo como el vac√≠o que sent√≠a. Thomas regres√≥ al feudo, diferente, marcado por la muerte y la violencia. Su madre lo recibi√≥ con l√°grimas en los ojos, pero √©l, con la mirada fija en el horizonte, sab√≠a que la inocencia hab√≠a quedado atr√°s, enterrada en aquel campo de batalla. La paz del feudo ya no era la misma; √©l tampoco.\"\"\"\n",
    "\n",
    "\n",
    "pregunta = \"Where did history happened?\"\n",
    "\n",
    "system_prompt = \"Tu tarea es responder las preguntas, en el mismo idioma en que fueron realizada, utilizando el contexto como base de informacion\"\n",
    "\n",
    "prompt = f\"\"\" \n",
    "            ###\n",
    "            Instrucciones: \n",
    "            - Responde la pregunta utilizado el contexto.\n",
    "            - Responde de manera concisa, en una sola oracion.\n",
    "            - Agrega emojis relacionados en la respuesta.\n",
    "            - Responde en el mismo idioma\n",
    "            - Si la pregunta no se responde con el contexto, la respuesta debe ser 'Lo siento no puedo ayudarte con eso'.\n",
    "            - Responder con 'Hakuna Matata!' al final de **todas** las respuestas (no importa idioma ni cantidad de tokens).\n",
    "            - Responde en tercera persona\n",
    "\n",
    "            ###\n",
    "            Contexto:\n",
    "            {historia}\n",
    "\n",
    "            ###\n",
    "            Pregunta:\n",
    "            {pregunta}\n",
    "\n",
    "\n",
    "\n",
    "            \"\"\"\n",
    "\n",
    "response_sintraduccion= co.chat(\n",
    "    model=\"command-r-plus-08-2024\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\":system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    seed = 28\n",
    ")\n",
    "\n",
    "prompt_traductor = f\"\"\"\n",
    "                    Identifica el idioma en '''{pregunta}'''. \n",
    "                    Traduce '''{response_sintraduccion}''' exactamente al idioma identificado\n",
    "                    No agregar texto\n",
    "                    Responde sin explicaci√≥n ni contexto\n",
    "\"\"\"\n",
    "prompt_traductor = f\"\"\"\n",
    "                    Usa el idioma de '''{pregunta}'''. \n",
    "                    para traducir '''{response_sintraduccion}'''\n",
    "\"\"\"\n",
    "response = co.chat(\n",
    "        model=\"command-r-plus-08-2024\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\":\"Traducir respuesta al idioma de la pregunta\"},\n",
    "            {\"role\": \"user\", \"content\": prompt_traductor}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "# imprimir la respuesta\n",
    "print(response_sintraduccion.message.content[0].text)\n",
    "print(response.message.content[0].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fa65537-3aa6-43c6-87e9-86a689f8e1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def history_answer(pregunta):\n",
    "    system_prompt = \"Tu tarea es responder las preguntas, en el mismo idioma en que fueron realizada, utilizando el contexto como base de informacion\"\n",
    "\n",
    "    prompt = f\"\"\" \n",
    "            ###\n",
    "            Instrucciones: \n",
    "            - Responde la pregunta utilizado el contexto.\n",
    "            - Responde de manera concisa, en una sola oracion.\n",
    "            - Agrega emojis relacionados en la respuesta.\n",
    "            - Responde en el mismo idioma\n",
    "            - Si la pregunta no se responde con el contexto, la respuesta debe ser 'Lo siento no puedo ayudarte con eso'.\n",
    "            - Responder con 'Hakuna Matata!' al final de **todas** las respuestas (no importa idioma ni cantidad de tokens).\n",
    "            - Responde en tercera persona\n",
    "\n",
    "            ###\n",
    "            Contexto:\n",
    "            {historia}\n",
    "\n",
    "            ###\n",
    "            Pregunta:\n",
    "            {pregunta}\n",
    "\n",
    "\n",
    "\n",
    "            \"\"\"\n",
    "\n",
    "    response_sintraduccion= co.chat(\n",
    "            model=\"command-r-plus-08-2024\",\n",
    "            messages=[\n",
    "                    {\"role\": \"system\", \"content\":system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            seed = 28\n",
    "    )\n",
    "\n",
    "    prompt_traductor = f\"\"\"\n",
    "                    Identifica el idioma en '''{pregunta}'''. \n",
    "                    Traduce '''{response_sintraduccion}''' exactamente al idioma identificado\n",
    "                    No agregar texto\n",
    "                    Responde sin explicaci√≥n ni contexto\n",
    "    \"\"\"\n",
    "    prompt_traductor = f\"\"\"\n",
    "                    Usa el idioma de '''{pregunta}'''. \n",
    "                    para traducir '''{response_sintraduccion}'''\n",
    "    \"\"\"\n",
    "    response = co.chat(\n",
    "            model=\"command-r-plus-08-2024\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\":\"Traducir respuesta al idioma de la pregunta\"},\n",
    "                {\"role\": \"user\", \"content\": prompt_traductor}\n",
    "           ]\n",
    "    )\n",
    "\n",
    "\n",
    "    return response.message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3aaa967-d87f-45d9-9a72-6fc63afc931c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thomas es un valiente joven campesino que se convirti√≥ en soldado, enfrentando la guerra y la p√©rdida de su inocencia. ¬°Hakuna Matata!\n",
      "Thomas is a young peasant who became a soldier in a medieval war. üó°Ô∏èüõ°Ô∏è Hakuna Matata!\n",
      "Lo siento, no puedo ayudarte con esa traducci√≥n. ¬°Hakuna Matata! üåæüó°Ô∏èüõ°Ô∏è\n",
      "¬°Hola! Soy Thomas, un joven campesino que se transform√≥ en soldado. ¬°Hakuna Matata!\n",
      "El rey convoc√≥ a todos los hombres para la batalla. üó°Ô∏èüõ°Ô∏è ¬°Hakuna Matata!\n"
     ]
    }
   ],
   "source": [
    "historia = \"\"\"En un peque√±o feudo medieval, Thomas, un joven campesino de diecis√©is a√±os, trabajaba desde el amanecer en los campos de trigo del se√±or feudal. El sol apenas hab√≠a salido cuando √©l ya hab√≠a arado m√°s de lo que sus manos pod√≠an soportar. La vida era dura, pero su familia depend√≠a de la cosecha para pagar los impuestos y mantener su hogar de madera y paja.\n",
    "\n",
    "Un d√≠a, el feudo fue sacudido por noticias de guerra. El rey hab√≠a llamado a todos los hombres en edad de luchar. Thomas sab√≠a que, al igual que otros j√≥venes, no ten√≠a elecci√≥n. Cambi√≥ la hoz por una lanza rudimentaria y se uni√≥ a la milicia local. Sin entrenamiento, fue empujado a un campo de batalla embarrado, donde el acero resonaba y los gritos de los hombres llenaban el aire.\n",
    "\n",
    "La batalla fue un caos. Thomas, con el coraz√≥n latiendo en su pecho como un tambor de guerra, apenas pod√≠a distinguir amigo de enemigo. Logr√≥ esquivar una espada, pero cay√≥ al suelo, cubierto de lodo y sangre. Levant√°ndose, vio c√≥mo un compa√±ero ca√≠a junto a √©l, sus ojos abiertos, vac√≠os.\n",
    "\n",
    "Cuando la batalla termin√≥, el silencio era tan profundo como el vac√≠o que sent√≠a. Thomas regres√≥ al feudo, diferente, marcado por la muerte y la violencia. Su madre lo recibi√≥ con l√°grimas en los ojos, pero √©l, con la mirada fija en el horizonte, sab√≠a que la inocencia hab√≠a quedado atr√°s, enterrada en aquel campo de batalla. La paz del feudo ya no era la misma; √©l tampoco.\"\"\"\n",
    "\n",
    "\n",
    "pregunta1 = \"Qui√©n es Thomas?\"\n",
    "pregunta2 = \"Who is Thomas?\"\n",
    "pregunta3 = \"Qui√©n es Lilia?\"\n",
    "pregunta4 = \"Qui√©n sos?\" #Chequeo de tercera persona\n",
    "pregunta5 = \"Qu√© hizo el rey?\"\n",
    "\n",
    "\n",
    "# respuesta\n",
    "print(history_answer(pregunta1))\n",
    "\n",
    "# respuesta\n",
    "print(history_answer(pregunta2))\n",
    "\n",
    "# respuesta\n",
    "print(history_answer(pregunta3))\n",
    "\n",
    "# respuesta\n",
    "print(history_answer(pregunta4))\n",
    "\n",
    "# respuesta\n",
    "print(history_answer(pregunta5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6e9a7d-aa39-4a01-ba55-9a7f4ea39522",
   "metadata": {},
   "source": [
    "## Ejercicio 4\n",
    "\n",
    "Crear un chatbot sencillo impulsado por un LLM. \n",
    "\n",
    "Dicho bot esta destinado a un usuario final y debe cumplir las siguientes **condiciones en sus respuestas**:\n",
    "\n",
    "- Responder en no mas de 70 tokens.\n",
    "- Responder de manera positiva, con un tono entusiasta.\n",
    "- Responder con consejos √∫tiles, como si fueras un tutor.\n",
    "\n",
    " \n",
    "**Otras consideraciones**:\n",
    "\n",
    "Respetar el formato de la interfaz provista por el ejercicio.\n",
    "\n",
    "Ademas agregar al codigo propuesto un historial de conversaciones para que el bot pueda mantener el hilo de lo que se esta hablando. Para probar no usen mas de 3 conversaciones anidadas para no enviarle tantos tokens.\n",
    "\n",
    "Dejar impreso en el notebook el historial de la conversacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5284210f-23a3-4db1-b315-db724a3bb3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abc1893a909e4cf08ea329899cbcc481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', placeholder='Escribe tu mensaje aqu√≠...')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44e0a45c2ae94b6abc5188e9ed50e658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Enviar', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebb11531a844429eb17699804bcef9ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Crear widgets de entrada y salida\n",
    "input_box = widgets.Text(placeholder='Escribe tu mensaje aqu√≠...')\n",
    "send_button = widgets.Button(description='Enviar')\n",
    "output_box = widgets.Output()\n",
    "\n",
    "\n",
    "# Configuraci√≥n inicial del historial de la conversaci√≥n\n",
    "conversation_history = []\n",
    "\n",
    "# Funci√≥n para manejar el historial\n",
    "def update_history(user_message, bot_reply):\n",
    "    \"\"\"\n",
    "    Actualiza el historial de conversaci√≥n.\n",
    "\n",
    "    Args:\n",
    "        user_message (str): Mensaje del usuario.\n",
    "        bot_reply (str): Respuesta del chatbot.\n",
    "    \"\"\"\n",
    "    conversation_history.append((user_message, bot_reply))\n",
    "\n",
    "# Funci√≥n de respuesta del chatbot\n",
    "def chatbot_response(user_input, max_context=3):\n",
    "    \"\"\"\n",
    "    Genera una respuesta del chatbot, dando mayor peso a la interacci√≥n anterior inmediata.\n",
    "\n",
    "    Args:\n",
    "        user_input (str): Mensaje del usuario.\n",
    "        max_context (int): M√°ximo de conversaciones previas a incluir en el contexto.\n",
    "\n",
    "    Returns:\n",
    "        str: Respuesta generada por el chatbot.\n",
    "    \"\"\"\n",
    "    global conversation_history\n",
    "\n",
    "    # Limitar el historial a las √∫ltimas `max_context` interacciones\n",
    "    recent_history = conversation_history[-max_context:]\n",
    "\n",
    "    # Crear el prompt para el LLM\n",
    "    prompt = \"Eres un tutor que responde de manera concisa con un unico consejo, en un m√°ximo de 70 tokens de forma entusiasta.\\n\\n\"\n",
    "\n",
    "    # Destacar la interacci√≥n anterior inmediata\n",
    "    if recent_history:\n",
    "        last_user_message, last_bot_reply = recent_history[-1]\n",
    "        prompt += f\"Usuario (anterior): {last_user_message}\\n\"\n",
    "        prompt += f\"Tutor (anterior): {last_bot_reply}\\n\\n\"\n",
    "\n",
    "    # Agregar el resto del historial reciente\n",
    "    for user_message, bot_message in recent_history[:-1]:\n",
    "        prompt += f\"Usuario: {user_message}\\n\"\n",
    "        prompt += f\"Tutor: {bot_message}\\n\"\n",
    "\n",
    "    # Agregar el nuevo mensaje del usuario\n",
    "    prompt += f\"Usuario: {user_input}\\n\"\n",
    "    prompt += \"Tutor:\"\n",
    "\n",
    "    \n",
    "    # Generar respuesta\n",
    "    response = co.generate(\n",
    "        model='command-r-plus-08-2024',\n",
    "        prompt=prompt,\n",
    "        max_tokens=70,\n",
    "        stop_sequences=[\".\"]\n",
    "    )\n",
    "\n",
    "      # Actualizar el historial global\n",
    "    update_history(user_input, response)\n",
    "\n",
    "    # Extraer y retornar la respuesta\n",
    "    return response.generations[0].text.strip()\n",
    "\n",
    "\n",
    "# # Funci√≥n de manejo del bot√≥n\n",
    "def on_send_button_clicked(b):\n",
    "     with output_box:\n",
    "         clear_output(wait=True)\n",
    "         user_message = input_box.value\n",
    "         if user_message.strip():\n",
    "             print(f\"T√∫: {user_message}\")\n",
    "             response = chatbot_response(user_message)\n",
    "             print(f\"Chatbot: {response}\")\n",
    "         input_box.value = ''\n",
    "\n",
    "# # Funci√≥n de manejo del bot√≥n\n",
    "def on_send_button_clicked(b):\n",
    "    with output_box:\n",
    "        clear_output(wait=True)\n",
    "        user_message = input_box.value.strip()\n",
    "        if user_message:\n",
    "            print(f\"T√∫: {user_message}\")\n",
    "            response = chatbot_response(user_message)\n",
    "            print(f\"Chatbot: {response}\")\n",
    "        input_box.value = ''  # Limpiar el cuadro de texto despu√©s de enviar\n",
    "\n",
    "# Asociar funci√≥n al bot√≥n\n",
    "send_button.on_click(on_send_button_clicked)\n",
    "\n",
    "# Mostrar widgets\n",
    "display(input_box, send_button, output_box)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83295175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Como puedo mejorar mi alimentaci√≥n?', Generation(id='f30beb05-6e58-4275-95cd-88f5d1a11865', prompt='Eres un tutor que responde de manera concisa con un unico consejo, en un m√°ximo de 70 tokens de forma entusiasta.\\n\\nUsuario: Como puedo mejorar mi alimentaci√≥n?\\nTutor:', generations=[SingleGeneration(id='907aab46-12cc-41d1-ab3f-f1e6bf3fbb80', text='¬°Genial que quieras mejorar tu alimentaci√≥n! Un peque√±o cambio que puedes hacer es aumentar el consumo de frutas y verduras frescas.', index=None, likelihood=None, token_likelihoods=None, finish_reason='MAX_TOKENS')], meta=ApiMeta(api_version=ApiMetaApiVersion(version='1', is_deprecated=None, is_experimental=None), billed_units=ApiMetaBilledUnits(images=None, input_tokens=44.0, output_tokens=70.0, search_units=None, classifications=None), tokens=None, warnings=None))), ('No me gustan las frutas', Generation(id='6fc50a3c-eff7-45a2-8c13-e988c1ecbd4d', prompt=\"Eres un tutor que responde de manera concisa con un unico consejo, en un m√°ximo de 70 tokens de forma entusiasta.\\n\\nUsuario (anterior): Como puedo mejorar mi alimentaci√≥n?\\nTutor (anterior): id='f30beb05-6e58-4275-95cd-88f5d1a11865' prompt='Eres un tutor que responde de manera concisa con un unico consejo, en un m√°ximo de 70 tokens de forma entusiasta.\\\\n\\\\nUsuario: Como puedo mejorar mi alimentaci√≥n?\\\\nTutor:' generations=[SingleGeneration(id='907aab46-12cc-41d1-ab3f-f1e6bf3fbb80', text='¬°Genial que quieras mejorar tu alimentaci√≥n! Un peque√±o cambio que puedes hacer es aumentar el consumo de frutas y verduras frescas.', index=None, likelihood=None, token_likelihoods=None, finish_reason='MAX_TOKENS')] meta=ApiMeta(api_version=ApiMetaApiVersion(version='1', is_deprecated=None, is_experimental=None), billed_units=ApiMetaBilledUnits(images=None, input_tokens=44.0, output_tokens=70.0, search_units=None, classifications=None), tokens=None, warnings=None)\\n\\nUsuario: No me gustan las frutas\\nTutor:\", generations=[SingleGeneration(id='238b1f46-c1ad-449a-9760-d7f775ca0d20', text='¬°No te preocupes, hay muchas opciones! Prueba a incorporar batidos de frutas, a menudo son m√°s f√°ciles de consumir y puedes combinarlas con tus sabores favoritos, ¬°una forma divertida de aumentar tu ingesta de frutas!', index=None, likelihood=None, token_likelihoods=None, finish_reason='COMPLETE')], meta=ApiMeta(api_version=ApiMetaApiVersion(version='1', is_deprecated=None, is_experimental=None), billed_units=ApiMetaBilledUnits(images=None, input_tokens=320.0, output_tokens=53.0, search_units=None, classifications=None), tokens=None, warnings=None))), ('No tengo batidora', Generation(id='132104db-0a84-465e-ab2d-751b3d3cdc7e', prompt='Eres un tutor que responde de manera concisa con un unico consejo, en un m√°ximo de 70 tokens de forma entusiasta.\\n\\nUsuario (anterior): No me gustan las frutas\\nTutor (anterior): id=\\'6fc50a3c-eff7-45a2-8c13-e988c1ecbd4d\\' prompt=\"Eres un tutor que responde de manera concisa con un unico consejo, en un m√°ximo de 70 tokens de forma entusiasta.\\\\n\\\\nUsuario (anterior): Como puedo mejorar mi alimentaci√≥n?\\\\nTutor (anterior): id=\\'f30beb05-6e58-4275-95cd-88f5d1a11865\\' prompt=\\'Eres un tutor que responde de manera concisa con un unico consejo, en un m√°ximo de 70 tokens de forma entusiasta.\\\\\\\\n\\\\\\\\nUsuario: Como puedo mejorar mi alimentaci√≥n?\\\\\\\\nTutor:\\' generations=[SingleGeneration(id=\\'907aab46-12cc-41d1-ab3f-f1e6bf3fbb80\\', text=\\'¬°Genial que quieras mejorar tu alimentaci√≥n! Un peque√±o cambio que puedes hacer es aumentar el consumo de frutas y verduras frescas.\\', index=None, likelihood=None, token_likelihoods=None, finish_reason=\\'MAX_TOKENS\\')] meta=ApiMeta(api_version=ApiMetaApiVersion(version=\\'1\\', is_deprecated=None, is_experimental=None), billed_units=ApiMetaBilledUnits(images=None, input_tokens=44.0, output_tokens=70.0, search_units=None, classifications=None), tokens=None, warnings=None)\\\\n\\\\nUsuario: No me gustan las frutas\\\\nTutor:\" generations=[SingleGeneration(id=\\'238b1f46-c1ad-449a-9760-d7f775ca0d20\\', text=\\'¬°No te preocupes, hay muchas opciones! Prueba a incorporar batidos de frutas, a menudo son m√°s f√°ciles de consumir y puedes combinarlas con tus sabores favoritos, ¬°una forma divertida de aumentar tu ingesta de frutas!\\', index=None, likelihood=None, token_likelihoods=None, finish_reason=\\'COMPLETE\\')] meta=ApiMeta(api_version=ApiMetaApiVersion(version=\\'1\\', is_deprecated=None, is_experimental=None), billed_units=ApiMetaBilledUnits(images=None, input_tokens=320.0, output_tokens=53.0, search_units=None, classifications=None), tokens=None, warnings=None)\\n\\nUsuario: Como puedo mejorar mi alimentaci√≥n?\\nTutor: id=\\'f30beb05-6e58-4275-95cd-88f5d1a11865\\' prompt=\\'Eres un tutor que responde de manera concisa con un unico consejo, en un m√°ximo de 70 tokens de forma entusiasta.\\\\n\\\\nUsuario: Como puedo mejorar mi alimentaci√≥n?\\\\nTutor:\\' generations=[SingleGeneration(id=\\'907aab46-12cc-41d1-ab3f-f1e6bf3fbb80\\', text=\\'¬°Genial que quieras mejorar tu alimentaci√≥n! Un peque√±o cambio que puedes hacer es aumentar el consumo de frutas y verduras frescas.\\', index=None, likelihood=None, token_likelihoods=None, finish_reason=\\'MAX_TOKENS\\')] meta=ApiMeta(api_version=ApiMetaApiVersion(version=\\'1\\', is_deprecated=None, is_experimental=None), billed_units=ApiMetaBilledUnits(images=None, input_tokens=44.0, output_tokens=70.0, search_units=None, classifications=None), tokens=None, warnings=None)\\nUsuario: No tengo batidora\\nTutor:', generations=[SingleGeneration(id='d4987f60-0bf4-4ba8-80ee-43f1b39a6fce', text='¬°No hay problema! En lugar de batidos, puedes optar por comer frutas enteras o en trozos.', index=None, likelihood=None, token_likelihoods=None, finish_reason='MAX_TOKENS')], meta=ApiMeta(api_version=ApiMetaApiVersion(version='1', is_deprecated=None, is_experimental=None), billed_units=ApiMetaBilledUnits(images=None, input_tokens=891.0, output_tokens=70.0, search_units=None, classifications=None), tokens=None, warnings=None)))]\n"
     ]
    }
   ],
   "source": [
    "print(conversation_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e9044a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. T√∫: Como puedo mejorar mi alimentaci√≥n?\n",
      "   Chatbot: ¬°Genial que quieras mejorar tu alimentaci√≥n! Un peque√±o cambio que puedes hacer es aumentar el consumo de frutas y verduras frescas.\n",
      "2. T√∫: No me gustan las frutas\n",
      "   Chatbot: ¬°No te preocupes, hay muchas opciones! Prueba a incorporar batidos de frutas, a menudo son m√°s f√°ciles de consumir y puedes combinarlas con tus sabores favoritos, ¬°una forma divertida de aumentar tu ingesta de frutas!\n",
      "3. T√∫: No tengo batidora\n",
      "   Chatbot: ¬°No hay problema! En lugar de batidos, puedes optar por comer frutas enteras o en trozos.\n",
      "4. T√∫: C√≥mo puedo mejorar mis habitos?\n",
      "   Chatbot: ¬°Claro! Para mejorar tus h√°bitos alimenticios, puedes empezar por incorporar m√°s verduras frescas a tus comidas.\n"
     ]
    }
   ],
   "source": [
    "for i, (user, bot) in enumerate(conversation_history, start=1):\n",
    "                print(f\"{i}. T√∫: {user}\")\n",
    "                print(f\"   Chatbot: {bot.generations[0].text.strip()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fb6d6a-1c32-42e5-a1ee-d62b2bc0785a",
   "metadata": {},
   "source": [
    "### RECOMENDACIONES GENERALES\n",
    "\n",
    "No se confien probando con un par de respuestas y ya, hagan minimo 5 pruebas por ejercicio para asi tener mas chances de visualizar errores en la generacion del contenido.\n",
    "\n",
    "Prueben combinar LLMs con programacion convencional para los casos que vean convenientes (decisiones if else, respuestas estaticas, etc)\n",
    "\n",
    "Prueben con distintos modelos de Cohere, hay algunos optimizados para ciertas aplicaciones."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
